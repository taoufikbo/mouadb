[{"content":"Kyverno is a dynamic admission controller that can be used to govern and enforce how a Kubernetes cluster is used.\nAdmission Controllers Let\u0026rsquo;s first start with admission controllers since Kyverno is an admission controller. In Kubernetes admission controllers are used to intercept requests going to the API servier and one of the two or both the things with them - mutate or/and validate. Kubernetes comes up with built-in admission controllers. The issue with these built-in admission controllers is that they are highly specific and different organizations may have different use cases with admission contollers not being fulfilled by these built-in admission controllers, therefore, for meeting these requirements we have dynamic admission controllers that can be developed as extensions and can be run as webhooks configured at runtime.\nAdmission control phases\nThe primary job of a admission controller is to validate the resources. If a resource is passed to an admission controller it will tell if it is allowed or not. And that is all what an admission controller does. But as we said Kyverno is more than just an admission controller. Kyverno acts as a admission controller and validates the resources but it also can change the resources transparently.\nIn this beginner friendly article, we will discuss what Kyverno is and how it works on theory, but before that let\u0026rsquo;s have a look at some basic terms:\nCustom resources Custom resources are the extensions of the Kubernetes API that are not available in the default Kubernetes installation. These are like additional stuff or customization we can add on Kubernetes. However, many Kubernetes core functions are now build using custom resources, this make Kubernetes very modular. A Kyverno policy is a standard Kubernetes custom resource.\nCustom Controllers The custom resources lets us store and retrieve structured data. But when we combine a custom resource with a custom controller, it provides us a declarative API. Custom controllers are used to encode domain knowledge for specific applications into an extension of Kubernetes API.\nAdmission Controllers In simplest terms, If a resource is passed to an admission controller it will tell if it is allowed or not. To explain further, the Kubernetes official documentation defines admission controller as - \u0026ldquo;An admission controller is a piece of code that intercepts requests to the Kubernetes API server prior to persistence of the object, but after the request is authenticated and authorized.\u0026rdquo; Admission controllers can either validate resources or mutate them, or do both.\nWhy Kyverno Kyverno is not just another admission controller, it can do much more than that. Where an ordinary admission controller can only validate the resources in the cluster. Kyverno not just validates the resources but can also change the resources transparently. when Kyverno receives the API requests, it can validate them, this can also be done in blocking mode.\nBlocking mode means it won\u0026rsquo;t prevent or allow cluster to run but specify that in a policy report.\nOther than this Kyverno also has the ability to mutate the resources transparently. Through Kyverno you can also generate Kubernetes resources. This means you can create new Kubernetes resources of any type or configuration based upon a policy that you define and install in the cluster.\nKyverno Policy A Kyverno policy can be one of:\nCluster scoped Namespace scoped Inside the Kyverno policy we have rules. A single policy has one or multiple rules. Each rule has a match block and can optionally also have an exclude block.\nKyverno\nYou can define scope of the resource you want to apply your policy to, using the following options. You can off-course choose one or multiple of these options:\nResource Kinds Resource Names Labels Annotations Namespaces Namespace Labels (Cluster)Roles Users Groups ServiceAccounts You can also declare what you want from the Policy, do you want to use it for Validation, mutating or something else. Here are the options you can choose in Kyverno:\nValidate the resource Mutate the resource Generate a resource Verify images Example of Kyverno Policy Here is a sample Kyverno Policy, A \u0026ldquo;ClusterPolicy\u0026rdquo; applies to the entire cluster. you can see we have a single rules block inside which we have a match block. We have set validationFailureAction to Audit therefore, it will be allowed even after the resource validation failure what but we should get a report if the resource validation fails.\nThis policy will perform validation of the pods and check the label. If the label is not provided with any value then it will send a message saying \u0026ldquo;The label app.kubernetes.io/name is must\u0026rdquo; .\nScreenshot-2023-09-29-072343\nYou can copy the same policy from the following code:\napiVersion: kyverno.io/v1 kind: ClusterPolicy metadata: name: require-labels spec: validationFailureAction: Audit background: true rules:\nname: check-for-labels match: any: resources: kinds: -Pod validate: message: \u0026ldquo;The label app.kubernetes.io/name is must\u0026rdquo; pattern: metadata: labels: app.kubernetes.io/name: \u0026ldquo;?*\u0026rdquo; Kyverno Usecases These are all the use cases of Kyverno, Feel free to skip them if you can not understand them as of now:\nSecurity Pod security Workload security Granular RBAC Workload isolation Image signing \u0026amp; verification Workload identity Reports Operations Namespaces-as-a-Service Clusters-as-a-Service Custom CA root certificate injection Automated resource generation Conditional patching of resources Inject sidecar container ConfigMap/Secret copying/syncing Stale resources cleanup Cost Governance Pod requests and limits Namespace quotas Team and app labels QoS management Auto-scalers Advantages of Kyverno over its other alternatives There are a lot of additional features that Kyverno provides compared with other alternative admission controllers, here are a few of them:\nEverything YAML - Simple to write All of the policies in Kyverno are written in YAML, Kyverno takes care of the heavy-lifting while you can simply use YAML for writing the Policy.\nMutating Resources Where an ordinary admission controller can only validate the resources in the cluster. Kyverno not just validates the resources but can also change the resources transparently.\nNamespaces-as-a-Service In Kyverno you can perform tasks like Namespaces-as-a-Service. You can simply create a namespace with a bunch of other resources that are in it. Kyverno can then generate all of those resources for you based on the manifest. You don\u0026rsquo;t have to run bash scripts or spit out resource quotas and limit ranges. You just have to simply write a Kyverno policy in YAML, install it in the cluster and version it. Kyverno will perform all the tasks for you after that.\nImage signing and verification Kyverno can also be used for image signing and verification purposes. Kyverno can do image verification without needing other bolt-on components. The Kyverno policy will need to know which images you want to check. Whenever that image gets built, it will get signed and pushed to the OCI registry.\nSome more features of Kyverno Some more features of Kyverno includes:\nMatching resources using label selectors and wildcards. Validating and mutating resources using overlays. Synchronizing configurations across namespaces. Blocking any non-conformant resources using admission controls, or report policy violations. Kyverno CLI - for testing policies and validating resources in the CI/CD pipeline. managing policies as code using familiar tools like git and kustomize. Conclusion As we discussed in previous sections, Kyverno is not just any admission controller, it is much more than that. An ordinary admission controller can only validate the resources in the cluster. Kyverno not just validates the resources but can also change the resources transparently. We discussed about Kyverno is this article we started off with an introduction to Kyverno, later we dicusses the terms like custom resources and custom controllers. Custom resources are the extensions of the Kubernetes API that are not available in the default Kubernetes installation. While custom controllers are used to encode domain knowledge for specific applications into an extension of Kubernetes API. We then say what Kyverno does? and an example of a Kyverno policy. At the end we discussed the advantages of Kyverno over other admission controllers and various usecases of Kyverno.\nThis marks the end of this article and we hope that this article helped you improve your understanding about Kyverno and policy management in Kubernetes.\nminikube start\nkubectl create -f https://github.com/kyverno/kyverno/releases/download/v1.10.0/install.yaml\nkubectl explain policy.spec.rules.preconditions\nKyverno primarily functions as an admission controller but not just another admission controller. Along with that Kyverno comes with a CLI that you can use outside of Kubernetes\nOnce Kyverno gets installed, it pull down a number of different configurations including there\u0026rsquo;s a bunch of roles it configures so there\u0026rsquo;s fine grain configuration there\u0026rsquo;s a security section in the docs which explains what each one of these roles are doing it also installs some webhooks which is what tells the api server to in you know contact Kyverno based on certain settings and then it\u0026rsquo;s creating some resources custom resources for policies policy reports\nWhy do we need Kyverno, one good example would be this scary piece of code in Kubernetes, if we enter this in the command line\nkubectl run r00t --restart=Never -ti --rm --image lol --overrides \u0026#39;{\u0026#34;spec\u0026#34;:{\u0026#34;hostPID\u0026#34;: true, \u0026#34;containers\u0026#34;:[{\u0026#34;name\u0026#34;:\u0026#34;1\u0026#34;,\u0026#34;image\u0026#34;:\u0026#34;public.ecr.aws/h1a5s9h8/alpine:latest\u0026#34;,\u0026#34;command\u0026#34;:[\u0026#34;nsenter\u0026#34;,\u0026#34;--mount=/proc/1/ns/mnt\u0026#34;,\u0026#34;--\u0026#34;,\u0026#34;/bin/bash\u0026#34;],\u0026#34;stdin\u0026#34;:true,\u0026#34;tty\u0026#34;:true,\u0026#34;securityContext\u0026#34;:{\u0026#34;privileged\u0026#34;:true}}]}}\u0026#39; What this is doing is it\u0026rsquo;s running a simple image but then it\u0026rsquo;s doing an nsenter and also elevating privileges for the Pod. So if we run this, the interesting thing that happens if we have no policies or no guardrails in place it that all we need is permissions to run a container in any namespace and we will have access to bash shell. With that we can look at all the containers running.\ncd var/log/containers\nls\nexit\nTutorial `minikube start\nkubectl create -f https://github.com/kyverno/kyverno/releases/download/v1.11.1/install.yaml\n","permalink":"//localhost:1313/blog/kyverno-intro/","summary":"Kyverno is a dynamic admission controller that can be used to govern and enforce how a Kubernetes cluster is used.\nAdmission Controllers Let\u0026rsquo;s first start with admission controllers since Kyverno is an admission controller. In Kubernetes admission controllers are used to intercept requests going to the API servier and one of the two or both the things with them - mutate or/and validate. Kubernetes comes up with built-in admission controllers. The issue with these built-in admission controllers is that they are highly specific and different organizations may have different use cases with admission contollers not being fulfilled by these built-in admission controllers, therefore, for meeting these requirements we have dynamic admission controllers that can be developed as extensions and can be run as webhooks configured at runtime.","title":"Introduction to Kubernetes Native Policy Management with Kyverno"},{"content":"Unit testing using Golang Let\u0026rsquo;s first start with what unit testing is. Unit Testing is a way of testing where the behavior of a unit of software is tested to determine if it works properly and exhibits the expected behavior. But why do we need unit testing? There are multiple reasons for that. See, how can we ensure that even if we change code, the code still works and there are no new bugs introduced, it\u0026rsquo;s better to detect them early than to wait and run the entire application in order to check a small code. In this way, unit tests help ensure quality code, help in catching bugs early, and provide a safety net if the code changes in the future.\nWhat is unit testing? As per IEEE (Institute for Electrical and Electronics Engineers), unit testing is the “testing of individual hardware or software units or groups of related units”. Unit testing is a software testing technique where individual components or units of a software application are tested in isolation.\nBy unit, we mean the smallest testable part of a code. mostly, it is a single function in Golang. The goal of unit testing is to ensure that each of these units functions correctly (produces expected results).\nThe term \u0026ldquo;unit\u0026rdquo; in unit testing refers to the smallest testable part of a software program, typically a single function, method, or class. The primary goal of unit testing is to ensure that each of these individual units of code functions correctly and produces the expected results.\nWhy Unit tests in Go? • Helps in verifying small changes (refactoring, debugging) quickly • Measures the quality of the code\n• Helps in understanding the complex logics\n• Helps in understanding the cause of failure quickly\n• Helps the reviewer to understand the fixes/changes\n• Great way to learn about a language as well as the project.\nLet\u0026rsquo;s create a basic unit test: Step 1. Start with initializing a go package\ngo mod init github.com/1shubham7/basic-unit-test\nStep 2. Download a unit testing package called go-money\ngo get github.com/Rhymond/go-money\nStep 3. Create this file structure:\nCreate a internal folder, inside that create a order folder, and inside the order folder, create a order.go file.\nStep 4. Start coding in the order.go file\npackage order import ( \u0026#34;github.com/Rhymond/go-money\u0026#34; \u0026#34;fmt\u0026#34; ) type Order struct { ID string CurrencyAlphaCode string Items []Item } type Item struct { ID string Quantity uint UnitPrice *money.Money } func (o Order) ComputeTotal() (*money.Money, error) { amount := money.New(0, o.CurrencyAlphaCode) for _, item := range o.Items { var err error amount, err = amount.Add(item.UnitPrice) if err!= nil { return nil, fmt.Errorf(\u0026#34;not adding item elements, error: %w\u0026#34;, err) } } return amount, nil } Step 5. Enter the following command to download testify\n/go get github.com/stretchr/testify\nStep 6. Create a order_test.go file and enter the following code inside it:\npackage order import ( \u0026#34;testing\u0026#34; \u0026#34;github.com/Rhymond/go-money\u0026#34; \u0026#34;github.com/stretchr/testify/assert\u0026#34; ) func TestOrder(t *testing.T) { o := Order{ ID: \u0026#34;100\u0026#34;, CurrencyAlphaCode: \u0026#34;INR\u0026#34;, Items: []Item{ { ID: \u0026#34;500\u0026#34;, Quantity: 2, UnitPrice: money.New(100, \u0026#34;INR\u0026#34;), }, }, } total, err := o.ComputeTotal() assert.NoError(t, err) assert.Equal(t, 200, total.Amount()) assert.Equal(t, \u0026#34;INR\u0026#34;, total.Currency()) } Step 7. Now this command is used to run all the unit test in that perticular directory, enter the following command:\ngo test ./...\nit will give you the result:\n--- FAIL: TestOrder (0.00s) order_test.go:25: Error Trace: D:/Files/Golang/Basic Unit Test/internal/order/order_test.go:25 Error: Not equal: expected: int(200) actual : int64(100) Test: TestOrder order_test.go:26: Error Trace: D:/Files/Golang/Basic Unit Test/internal/order/order_test.go:26 Error: Not equal: expected: string(\u0026#34;INR\u0026#34;) actual : *money.Currency(\u0026amp;money.Currency{Code:\u0026#34;INR\u0026#34;, NumericCode:\u0026#34;356\u0026#34;, Fraction:2, Grapheme:\u0026#34;₹\u0026#34;, Template:\u0026#34;$1\u0026#34;, Decimal:\u0026#34;.\u0026#34;, Thousand:\u0026#34;,\u0026#34;}) Test: TestOrder FAIL FAIL github.com/1shubham7/basic-unit-test/internal/order 1.001s FAIL Step 8. to fix this up, we have to make some changes in the code:\nMake these changes to the code:\norder.go:\npackage order\nimport ( \u0026#34;github.com/Rhymond/go-money\u0026#34; \u0026#34;fmt\u0026#34; ) type Order struct { ID string CurrencyAlphaCode string Items []Item } type Item struct { ID string Quantity uint UnitPrice *money.Money } func (o Order) ComputeTotal() (*money.Money, error) { amount := money.New(0, o.CurrencyAlphaCode) for _, item := range o.Items { var err error amount, err = amount.Add(item.UnitPrice.Multiply(int64(item.Quantity))) if err!= nil { return nil, fmt.Errorf(\u0026#34;not adding item elements, error: %w\u0026#34;, err) } } return amount, nil } order_test.go:\npackage order import ( \u0026#34;testing\u0026#34; \u0026#34;github.com/Rhymond/go-money\u0026#34; \u0026#34;github.com/stretchr/testify/assert\u0026#34; ) func TestOrder(t *testing.T) { o := Order{ ID: \u0026#34;100\u0026#34;, CurrencyAlphaCode: \u0026#34;INR\u0026#34;, Items: []Item{ { ID: \u0026#34;500\u0026#34;, Quantity: 2, UnitPrice: money.New(100, \u0026#34;INR\u0026#34;), }, }, } total, err := o.ComputeTotal() assert.NoError(t, err) assert.Equal(t, int64(200), total.Amount()) assert.Equal(t, \u0026#34;INR\u0026#34;, total.Currency().Code) } Now if you enter the same command:\ngo test ./...\nIt works perfectly fine: And that\u0026rsquo;s how we create a unit test. See you in some next tutorial. Thanks for reading.\n","permalink":"//localhost:1313/blog/testing/","summary":"Unit testing using Golang Let\u0026rsquo;s first start with what unit testing is. Unit Testing is a way of testing where the behavior of a unit of software is tested to determine if it works properly and exhibits the expected behavior. But why do we need unit testing? There are multiple reasons for that. See, how can we ensure that even if we change code, the code still works and there are no new bugs introduced, it\u0026rsquo;s better to detect them early than to wait and run the entire application in order to check a small code.","title":"Unit testing using Golang - a beginner's guide"},{"content":"Let\u0026rsquo;s first start with a quick intro about what GSoC is :\nSo, GSoC (Google Summer of Code) is an annual program launched by Google that offers university students from around the world the opportunity to work on open source software projects during the summer break. The program aims to bring together talented students, open source organizations, and mentors to contribute to open source software development and expand access to key technology initiatives.\nThere were about 43,000 applicants and about 7,700 proposals were submitted. Out of which 960 proposals were accepted. So, every 1 in 8 proposals was submitted, making GSoC at least lesser competitive than the IIT-JEE exam.\nMy Proposal I got to know about GSoC very early but due to my college exams and also me focusing more on my skills rather than open source I messed up this great opportunity. my semester exams ended on 1 April 2023 and the last date for proposal submission was 4th April 2023. I completed my proposal just 15 min before the deadline.\nHere is the link to my LinkedIn and Twitter where I have uploaded my proposal since I could not find any options in Hashnode to upload a PDF.\nLinkedIn : GSOC/1shubham7\nMistakes I made Mistake 1. Thinking I have to be perfect in order to contribute to open source. I thought that I must at least know 90% of the technology in order to contribute to such complex code bases while the truth is open source has something for everybody. You can start your contribution journey by solving the \u0026ldquo;Good First Issues\u0026rdquo;. Here is a link to a great website that finds you good first issues for the technology you are decent at:\ngoodfirstissue.dev\nJust go and try contributing, learn how to set up the project locally and contribute with whatever little knowledge you have, Of course, it\u0026rsquo;s even better you if have good knowledge of the technology.\nMistake 2. To select the wrong project. Go to the GSoC website and have a look at the organizations coming there, there are some organizations that are not able to complete their projects. Make sure to see the project history of the organizations. Make sure that the organization is consistently participating in GSoC every year and getting the projects done. For me, I choose a good organization but the project I was trying to contribute to was not very active, there was very less activity in the GitHub repo of that project.\nMistake 3. Choose a project with active mentors Learn from the mistakes I made, do check out the GitHub repo of the project before selecting it, and make sure that the project members and the mentors are active and helping newcomers with their queries. It is very rare that an inactive project gets completed.\nMistake 4. Start contributing early The earlier you start, the better it is. Make sure you start contributing to the project specifically at least 3-4 months and start contributing to any projects from now so to have a stronger GitHub profile.\nMistake 5. (You can ignore this one depending on your situation) I did not study much for college exams but I have now realized that I could have even studied lesser, I was easily fooled by my teachers since it was my first semester, now that I am in my second sem, I study lesser and focus more on open-source. You can ignore this advice depending on your situation. Since I come from a tier-3 college, I know we don\u0026rsquo;t have good placements so I am not even considering college placements, I am prepping for off-campus placements. If you are from a decent college, do focus a little bit more on your college exams.\nConclusion : In conclusion, as someone who missed out on GSoC 2023 due to mistakes made during the application process, I hope that my experience and advice can help future applicants avoid similar mistakes. I learned that open source has something for everyone, and that contributing to projects with active mentors and established project histories can increase one\u0026rsquo;s chances of being accepted into GSoC. I also realized that starting early and consistently contributing to open source projects can help build a strong GitHub profile, which can benefit not only GSoC applications but also future career opportunities. I encourage all students to consider applying for GSoC and not be discouraged by any initial challenges. The program provides a valuable learning opportunity and a chance to contribute to the open source community.\nThese were the mistakes I made. Hope you learn from my mistakes and have a beautiful GSoC journey. Hope this article will help you, if you are reading this and in the future you get selected, do tag me on Twitter: 1Shubham7. I will also be applying for GSoC2024, in the second year of my college.\nI wish you all the luck with your GSoC. Thank you for reading.\nMy Socials Twitter: 1Shubham7\nGitHub: 1Shubham7\nLinkedIn: Shubham Singh\n","permalink":"//localhost:1313/blog/gsoc/","summary":"Let\u0026rsquo;s first start with a quick intro about what GSoC is :\nSo, GSoC (Google Summer of Code) is an annual program launched by Google that offers university students from around the world the opportunity to work on open source software projects during the summer break. The program aims to bring together talented students, open source organizations, and mentors to contribute to open source software development and expand access to key technology initiatives.","title":"5 Mistakes to Avoid for cracking GSoC Proposal: Lessons from My GSoC'23 Experience"},{"content":"Hey there! So, remember when I mentioned Storyblok in my previous blog? Well, guess what? I discovered something super cool called the Storyblok Ambassadors Program! I was so intrigued that I decided to sign up myself. And let me tell you, it involved a bit of research, but it was totally worth it!\nNow, let\u0026rsquo;s embark on this journey together and explore what the Storyblok Ambassadors Program has to offer. We\u0026rsquo;ll dive into some interesting points that I stumbled upon while scrolling through their website. Get ready for some insider knowledge dose!\nWhat is the Storyblok Ambassadors Program ? The Storyblok Ambassadors Program is an initiative designed to recognize and empower individuals who are passionate about Storyblok and its mission. It\u0026rsquo;s a community-driven program that brings together enthusiastic advocates of the platform and provides them with opportunities for growth, collaboration, and recognition.\nAs a Storyblok Ambassador, you become part of an exclusive group of individuals who are dedicated to promoting and supporting Storyblok. The program aims to reward and amplify your expertise, contributions, and engagement within the Storyblok community.\nWhere and How to apply ? To apply for the Storyblok Ambassadors Program, you can follow these steps:\nVisit the Storyblok website: Go to the official Storyblok website and search for the \u0026ldquo;Storyblok Ambassadors\u0026rdquo; Option. Or just Click this.\nRead the program details: Take your time to read through the details and requirements of the Ambassadors Program. Understand the expectations, benefits, and any specific criteria for becoming an ambassador.\nClick on \u0026ldquo;Apply now\u0026rdquo; and this will take you to a google forms page. Fill in your accurate information on pages 1 and 2.\nPage 3 is the most important one. Here you have to answer three questions. Do answer them honestly and make sure to not add any fake information or make spelling or grammatical mistakes.\nSubmit your application: Once you have completed the application, submit it.\nFollow up, if necessary: If you haven\u0026rsquo;t received any confirmation or response after a reasonable period, you can consider reaching out to the Storyblok team through their contact channels. Inquire about the status of your application and express your continued interest in the program.\nAmbassador Perks \u0026amp; Benefits These are the Perks and benefits of the program, I took these from the official website.\nCareer support You will be receiving mentorship and guidance as part of your career development.\nEarly access We will ask for your opinion on the next features and give you the privilege to try them before they go live.\nRecognition You will receive appreciation for your contributions towards Storyblok across our social media channels.\nResources You get to receive swag and sponsorship resources for your activities on case to case basis.\nGlobal Community You become part of the Global Exclusive Network of people advocating for Headless CMS space.\nSpecial swags You will receive a Storyblok t-shirt, a special Storyblok mug, stickers and more.\nConclusion: In conclusion, the Storyblok Ambassadors Program is a unique opportunity for individuals who are passionate about Storyblok and want to get involved in the community. The program offers several Benefits such as career support, early access to upcoming features, recognition, special swags, and more.\nBeing a Storyblok Ambassador is not just about perks and benefits, but it\u0026rsquo;s also about being part of a global community of people who share a common interest in promoting and supporting a powerful platform that enables businesses and developers to create unique and compelling digital experiences.\nIf you are interested in becoming a Storyblok Ambassador, don\u0026rsquo;t hesitate to apply and join the community. It\u0026rsquo;s a chance to grow your skills, expand your network, and make a difference in the world of Headless CMS.\nThank you for reading this far. Do follow me for more such blogs related to tech opportunities and computer science. If you found it helpful do give it a heart.\nThank you for your time.\n","permalink":"//localhost:1313/blog/storyblokambassador/","summary":"Hey there! So, remember when I mentioned Storyblok in my previous blog? Well, guess what? I discovered something super cool called the Storyblok Ambassadors Program! I was so intrigued that I decided to sign up myself. And let me tell you, it involved a bit of research, but it was totally worth it!\nNow, let\u0026rsquo;s embark on this journey together and explore what the Storyblok Ambassadors Program has to offer. We\u0026rsquo;ll dive into some interesting points that I stumbled upon while scrolling through their website.","title":"All about the Storyblok Ambassadors Program"},{"content":"Databases: just a digital tool that stores and organizes information in a way that makes it easy to access and merge. Therefore now we can write a technical definition of Databases that is\n\u0026ldquo;In technical language, a database is a structured collection of data that is stored electronically on a computer system. It is designed to efficiently manage, store, retrieve, and update large amounts of data.\u0026rdquo;\nso where are databases needed?\nanywhere where you can think you need to store data in a proper manner. From your class\u0026rsquo;s students list to Facebook\u0026rsquo;s user list.\ntypes of databases :\nRelational Databases - These databases store data in tables with rows and columns, and the relationships between tables are defined by keys.\nNoSQL Databases - These databases are designed to handle unstructured data and can store data in a variety of formats, including key-value pairs, documents, and graphs.\nObject-oriented Databases - These databases store data as objects, which can include data and code. They are often used in software development. (You must have heard of Object-oriented Programming in Java, c++, etc)\nGraph Databases - These databases store data in nodes and edges and are particularly useful for storing data with complex relationships.\nHierarchical Databases - These databases organize data in a tree-like structure, with each node having one parent and multiple children.\nNetwork Databases - These databases store data in a more flexible structure than hierarchical databases, allowing nodes to have multiple parents and children.\nDistributed Databases - These databases are spread across multiple computers or servers, allowing for increased scalability and fault tolerance.\nAnd that\u0026rsquo;s it you are done with databases. Make sure to check out our blog on DBMS, the continuation of this topic.\n","permalink":"//localhost:1313/blog/database/","summary":"Databases: just a digital tool that stores and organizes information in a way that makes it easy to access and merge. Therefore now we can write a technical definition of Databases that is\n\u0026ldquo;In technical language, a database is a structured collection of data that is stored electronically on a computer system. It is designed to efficiently manage, store, retrieve, and update large amounts of data.\u0026rdquo;\nso where are databases needed?","title":"Databases - the easy way"},{"content":"Python includes 6 types of built-in datatypes -\nNumeric datatype\nBoolean datatype\nSequence datatype\nSets\nDictionaries\nNone\nNumeric datatype this datatype includes integer, float, and complex numbers. Unlike other languages, python allows you to reassign float value to a variable with integer or vice versa.\na = 10 a = 10.5 print(a) #this will output 10.5 Boolean datatype This is a special data type that represents one of two possible values: True or False. Boolean values are often used in conditional statements and loops. Remember the first letter in \u0026ldquo;True\u0026rdquo; and \u0026ldquo;False\u0026rdquo; must be capitalized.\na = True if (a==True): print(\u0026#34;a is true\u0026#34;) else : print(\u0026#34;a is not true\u0026#34;) Sequence These include strings, lists, tuples, and byte sequences. Strings are used to represent textual data, while lists and tuples are used to store collections of items. Byte sequences are similar to strings but represent binary data.\nmy_tuple = (\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;,\u0026#34;c\u0026#34;,\u0026#34;d\u0026#34;,5,6,7,8) print(my_tuple) Sets These are unordered collections of unique items. Python also has a frozenset type that is similar to sets, but is immutable.\nmy_set = {1,2,3,4} print(my_set) Dictionaries These are unordered collections of key-value pairs. They are used to store and retrieve data based on a unique value.\nmy_dict = {\u0026#34;name\u0026#34;:\u0026#34;Shubham\u0026#34; , \u0026#34;age\u0026#34;:19} print(my_dict[\u0026#39;name\u0026#39;]) print(my_dict) None This is a special data type that represents the absence of a value. In other languages like Java, C++, c, Javascript, etc null is used rather than None.\na = null1\nPlease Follow my coming blogs on related topics.\nThank you for your time.\n","permalink":"//localhost:1313/blog/datainpython/","summary":"Python includes 6 types of built-in datatypes -\nNumeric datatype\nBoolean datatype\nSequence datatype\nSets\nDictionaries\nNone\nNumeric datatype this datatype includes integer, float, and complex numbers. Unlike other languages, python allows you to reassign float value to a variable with integer or vice versa.\na = 10 a = 10.5 print(a) #this will output 10.5 Boolean datatype This is a special data type that represents one of two possible values: True or False.","title":"Datatypes in Python"},{"content":"What is DBMS? if you have created or are going to create a database, obviously, you will have to add, remove, and edit the data in it (i.e. manage data in it) - DBMS can be used for that.\nIn technical language, \u0026ldquo;a DBMS (Database Management System) is a software system that allows users to store, retrieve, modify, and manage data in a database. It provides a structured way to organize and manage large amounts of data efficiently and securely.\u0026rdquo;\nClassification : there are mainly 4 types of DBMS -\nRelational Database Management System (RDBMS) It is the most commonly used DBMS type. In this type of DBMS, data is organized into tables, and relationships between tables are established using keys. You must have heard about this kind of DBMS. Some examples are MySQL, Oracle, PostgreSQL\nObject-Oriented Database Management System (OODBMS) In this type of DBMS, data is stored in the form of objects. OODBMS is mostly used for developing object-oriented applications. Examples of OODBMS are Zope and Versant.\nHierarchical Database Management System (HDBMS) In this type of DBMS, data is organized in a tree-like hierarchical structure. HDBMS is very useful for handling a large amount of unchanging data with a defined hierarchy. Examples of HDBMS include IBM\u0026rsquo;s Information Management System (IMS).\nNetwork Database Management System In this type of DBMS, data is organized in a more flexible network model. Network DBMS is used to store complex data structures that contain many-to-many relationships by allowing each record to have multiple parent and child records. Examples of Network DBMS include Integrated Data Store (IDS) and Integrated Database Management System (IDMS).\nConclusion In conclusion, there are four main types of Database Management Systems (DBMS) which include the Relational Database Management System (RDBMS), Object-Oriented Database Management System (OODBMS), Hierarchical Database Management System (HDBMS), and Network Database Management System. Each of these DBMS types has its unique way of organizing data, and they can be used for different purposes depending on the requirements of an application. So, understanding the different types of DBMS can help developers choose the right type of data management system for their applications.\n","permalink":"//localhost:1313/blog/dbms/","summary":"What is DBMS? if you have created or are going to create a database, obviously, you will have to add, remove, and edit the data in it (i.e. manage data in it) - DBMS can be used for that.\nIn technical language, \u0026ldquo;a DBMS (Database Management System) is a software system that allows users to store, retrieve, modify, and manage data in a database. It provides a structured way to organize and manage large amounts of data efficiently and securely.","title":"DBMS - the easy way"},{"content":"You must have heard of SCSS or SASS, but do you know the full form of the two tools, how similar these two terms are ? and what are the differences between them? join me in my exploration of these two CSS Pre-processors.\nWhat is SASS ? SASS (Syntactically Awesome Style Sheets) is a CSS pre-processor that allows you to write more maintainable and flexible code for your stylesheets.\nSass works by providing a set of extensions to CSS, which are then compiled to standard CSS syntax, so they can be used in your web project. Here is an example of how a file with SASS looks like.\n$primary-color: #ff0000; $secondary-color: #00ff00; @mixin center-element { display: flex; justify-content: center; align-items: center; } .header { background-color: $primary-color; color: #ffffff; padding: 10px; h1 { font-size: 24px; margin-bottom: 10px; } \u0026amp;.large { font-size: 32px; } \u0026amp;.small { font-size: 18px; } } .container { @include center-element; background-color: $secondary-color; height: 200px; width: 200px; } What is SCSS ? SCSS stands for Sassy CSS. It is also a CSS preprocessor. SCSS is a superset of CSS, which means that any valid CSS code is also valid SCSS code. SCSS syntax is similar to CSS syntax with some additional features and enhancements, such as variables, nesting, mixins, inheritance, and more.\nSCSS can help to shorten your CSS code, make it more maintainable, and easier to read. For example, you can define variables in SCSS, which allows you to use them throughout your CSS code.\nExample of SCSS code: $primary-color: #007bff; $secondary-color: #6c757d; @mixin center-element { display: flex; align-items: center; justify-content: center; } .container { width: 100%; .header { background-color: $primary-color; color: white; padding: 20px; h1 { font-size: 24px; } } .main { background-color: white; padding: 20px; .content { margin-bottom: 20px; p { color: $secondary-color; } } } .footer { background-color: $secondary-color; color: white; padding: 20px; } } .centered-box { @include center-element; width: 200px; height: 200px; background-color: $primary-color; color: white; } Difference between SCSS and SASS: SCSS SCSS is a superset of CSS, which means that any valid CSS code is also valid SCSS code.\nSCSS uses the same syntax as CSS, with curly braces {} and semicolons ;. It supports all the features of CSS, including nested selectors, variables, mixins, and more. SCSS files have the .scss file extension. SASS Sass has its own syntax, which is more concise and indentation-based.\nIt doesn\u0026rsquo;t use curly braces {} or semicolons ;. Instead, indentation is used to indicate nesting and separate properties. It doesn\u0026rsquo;t require the use of brackets or semicolons, which can make the code look cleaner and more readable. Sass supports all the features of SCSS, including nested selectors, variables, mixins, and more. Sass files have the .sass file extension. Conclusion In conclusion, SCSS and SASS are both CSS pre-processors that allow developers to write more maintainable, flexible, and organized code by extending the capabilities of standard CSS syntax. SCSS is a superset of CSS and uses the same syntax as CSS, while SASS has its own syntax that is more concise and uses indentation instead of curly braces and semicolons. Both of these preprocessors provide features such as variables, nesting, mixins, inheritance, and more, which can help to make code more readable and maintainable. It\u0026rsquo;s up to personal preference which pre-processor to use, and both have their pros and cons.\nThank you for reading.\nFollow me for more such blogs.\n","permalink":"//localhost:1313/blog/sass/","summary":"You must have heard of SCSS or SASS, but do you know the full form of the two tools, how similar these two terms are ? and what are the differences between them? join me in my exploration of these two CSS Pre-processors.\nWhat is SASS ? SASS (Syntactically Awesome Style Sheets) is a CSS pre-processor that allows you to write more maintainable and flexible code for your stylesheets.\nSass works by providing a set of extensions to CSS, which are then compiled to standard CSS syntax, so they can be used in your web project.","title":"Difference between SASS and SCSS"},{"content":"During our Web development journey will all get to hear the term - \u0026ldquo;API\u0026rdquo;. Some of us must have used some APIs, but not many know about what API actually is and how to play around with API. Join me in this article where we dive deep into the world of API and understand the concepts of API from beginner to advanced.\nWhat is API? The full form of API is Application Programming Interface. In simplest terms, API is a contract that allows code to talk to some other code. It serves as a bridge that enables a seamless exchange of data and functionality between various systems, enabling developers to access and utilize the features of another application or service without having to understand its internal workings.\nAPIs define a standardized way for different software components to interact, providing a layer of abstraction that simplifies development and integration. They typically consist of a collection of pre-defined functions, classes, or endpoints that developers can use to request or exchange data, perform operations, or access specific functionalities of the underlying system.\nWhy do we need API? It\u0026rsquo;s very basic, for making a weather app - would you launch satellites or just use a weather API?\nSome more examples of why we need API are:\nSocial Media Integration: Social media platforms like Facebook, Twitter, and Instagram provide APIs that allow developers to integrate their applications with these platforms. This integration enables users to log in using their social media accounts, share content, and access social features within the application.\nPayment Gateways: APIs offered by payment gateway providers such as PayPal, Stripe, and Braintree allow developers to incorporate secure payment processing functionality into their applications. This enables users to make online payments using different payment methods.\nMapping and Geolocation Services: APIs provided by mapping and geolocation services like Google Maps and Mapbox enable developers to embed maps, geocoding, and routing functionality into their applications. These APIs provide features such as displaying locations, calculating distances, and finding directions.\nWeather Data: Weather APIs, such as those offered by OpenWeatherMap and Weather Underground, provide access to real-time and forecast weather data. Developers can utilize these APIs to display weather information within their applications, enabling users to check current weather conditions or plan for future events.\nE-commerce Platforms: APIs offered by e-commerce platforms like Shopify and WooCommerce allow developers to create online stores, manage inventory, process orders, and retrieve product information. These APIs enable seamless integration between e-commerce platforms and custom applications.\nEmail Services: Email service providers like SendGrid and Mailchimp offer APIs that allow developers to send and manage emails programmatically. This enables applications to send transactional emails, newsletters, and marketing campaigns.\nCloud Services: Cloud computing providers such as Amazon Web Services (AWS), Microsoft Azure, and Google Cloud Platform offer APIs for various services like storage, computing, and database management. Developers can leverage these APIs to build scalable and flexible cloud-based applications.\nAPI Architectures There are several types of API architectures commonly used in web development. Here are three prominent ones:\nREST (Representational State Transfer) REST is a widely adopted architectural style for designing networked applications. RESTful APIs utilize the principles of the HTTP protocol and leverage its methods (GET, POST, PUT, DELETE, etc.) to perform operations on resources. REST APIs typically use URLs (Uniform Resource Locators) to identify resources and employ different HTTP status codes to indicate the outcome of a request. They emphasize statelessness, scalability, and interoperability, making them popular for building web services.\nSOAP (Simple Object Access Protocol) SOAP is an XML-based protocol that enables communication between applications over a network. SOAP APIs define a strict structure for request and response messages using XML schemas. They rely on the XML format for data representation and typically use the POST method for communication. SOAP APIs often employ Web Services Description Language (WSDL) to describe the available operations, message formats, and service endpoints. SOAP APIs are known for their strong message-level security and support for advanced features such as transactions and reliability.\nGraphQL GraphQL is an open-source query language and runtime for APIs developed by Facebook. It allows clients to request precisely the data they need, eliminating over-fetching or under-fetching of data common in traditional REST APIs. With GraphQL, clients can send queries specifying the desired data structure, and the server responds with a JSON payload containing only the requested data. This flexible and efficient approach to data fetching makes GraphQL popular for applications with complex data requirements and enables clients to aggregate data from multiple sources in a single request.\nThese are just a few examples of API architectures, and there are other variations and hybrid approaches as well. The choice of API architecture depends on factors such as the project requirements, scalability needs, interoperability considerations, and the preferences of the development team.\nConclusion In conclusion, APIs are the lifeblood of modern web development, enabling seamless communication and integration between different applications and services. They provide a standardized way for software components to interact, allowing developers to leverage the functionality of external systems without needing to understand their internal complexities.\nThroughout this article, we\u0026rsquo;ve explored the world of APIs from beginner to advanced levels. We\u0026rsquo;ve learned that APIs serve as the bridge that connects applications, enabling us to incorporate social media integration, payment gateways, mapping services, weather data, e-commerce functionalities, email services, and cloud computing capabilities into our own projects with ease.\nWe\u0026rsquo;ve also touched upon different API architectures, such as REST, SOAP, and GraphQL, each with its own strengths and areas of application. Understanding these architectures empowers us to make informed decisions when designing and implementing APIs in our projects.\nHope you gained some valuable insights. Do follow me for more such articles.\nThank you for your time.\n","permalink":"//localhost:1313/blog/api/","summary":"During our Web development journey will all get to hear the term - \u0026ldquo;API\u0026rdquo;. Some of us must have used some APIs, but not many know about what API actually is and how to play around with API. Join me in this article where we dive deep into the world of API and understand the concepts of API from beginner to advanced.\nWhat is API? The full form of API is Application Programming Interface.","title":"Everything about API explained!!"},{"content":"What are artifacts? In the broadest sense, artifacts are objects or items created or modified by humans that have some cultural significance. Similarly, In the context of DevOps, artifacts are files or sets of files that are produced by the build process of a software development project.\nYou must have heard of JAR files, ZIP files or this one for sure - Docker Images. Yes, These are also Artifacts.\nThese files are usually generated by a build tool (such as Maven, Gradle, or Ant for Java projects), which takes the source code and turns it into an executable program that can be run on a target environment.\nArtifact Repository : An artifact repository is a tool used in software development that stores and manages artifacts produced during the software build process. It serves as a central repository for storing, sharing and distributing.\nNote : every artifact format (ZIP, JAR, etc) needs a different artifact repository.\nNow a project being built by large start-ups like RedHat, Civo, Zulip, or your next company will surely have files or artifacts written in multiple languages. Some in Java, some in Golang and some in Javascript. Therefore they will require different software for every Artifact repository will be really chaotic and complex for the Engineers. To solve this problem we have Artifact Repository Managers.\nArtifact Repository Manager : An artifact repository manager is a tool used to manage and store artifacts produced during the software development lifecycle. It is a type of artifact repository but with additional features and functionalities aimed at managing the artifact repository effectively.\nNexus is a very popular artifact repository manager. Artifactory and Apache Archiva are two more popular artifact repository managers.\nConclusion: In conclusion, artifacts are files or sets of files produced during the software build process, which are stored and managed by artifact repository managers. This helps in effective management, sharing, and distribution of artifacts across the software development lifecycle. Popular artifact repository managers include Nexus, Artifactory, and Apache Archiva, each with their own unique features and capabilities aimed at managing artifact repositories effectively.\nThank you for reading.\n","permalink":"//localhost:1313/blog/artifacts/","summary":"What are artifacts? In the broadest sense, artifacts are objects or items created or modified by humans that have some cultural significance. Similarly, In the context of DevOps, artifacts are files or sets of files that are produced by the build process of a software development project.\nYou must have heard of JAR files, ZIP files or this one for sure - Docker Images. Yes, These are also Artifacts.\nThese files are usually generated by a build tool (such as Maven, Gradle, or Ant for Java projects), which takes the source code and turns it into an executable program that can be run on a target environment.","title":"Everything about Artifacts for DevOps"},{"content":"As someone who got to know the importance of developing a personal brand and learning in public, I restarted my blogging journey two months ago with Hashnode. Prior to that, I had been actively writing blogs on various platforms, including Blogger and WordPress for the past two years. Through this experience of two years of other blogging platforms and a short 2 months at Hashnode, I have firsthand experience of how powerful Hashnode and Hashnode Pro are compared to their competitors.\nJoin me on an exploration of my experience with Hashnode Pro. Together, let\u0026rsquo;s uncover the remarkable features, untap the potential for monetization, dive into advanced analytics, witness the transformative power of connecting with a vibrant community of like-minded individuals. how Hashnode Pro has redefined the way I approach blogging.\nFirstly, let me clarify that I have not purchased the Hashnode Pro subscription (due to financial constraints). However, I have read multiple blogs and articles about it, and I believe I now have enough knowledge to talk about it.\nFeatures Starting with the features, here are some of the features of Hashnode pro:\nCustom domain: You can connect your own custom domain to your Hashnode blog, to make it look more professional.\nCustom CSS: Hashnode Pro users can add custom CSS to their blog. This means that you can tweak the design of your blog to your liking without any limitations. While other will have a monotonous theme, you would stand out from crowd.\nNewsletters: You can create beautiful newsletters and send them to your readers with Hashnode Pro. Newsletters are an effective way to keep your readers engaged and up to date with your latest content.\nSubscriber Management: You can manage your subscribers on Hashnode Pro. You can view your subscriber list, export it, and analyze it to improve your blogging strategy. Similar to YouTube analytics, you can know how your subcribers are and device a better strategy to write the most helpful and most viewed blogs.\nAdvanced Analytics: Hashnode Pro users get access to advanced analytics such as real-time traffic, audience demographics, and engagement metrics.\nCollaborate with teams: You can use Hashnode pro to collaborate with your team members on your blog. Team members can contribute to your posts, edit them, and even publish them.\nNo Ads: Another advantage of Hashnode Pro is that it does not show any ads on your blog. Basically your viewers get to see some ads when they read your blog. That is done by Hashnode to sustain their economics since they are allowing you to use there platform for free. With Hashnode pro, you can have a ad free blog so that your user can have a better experience of reading your blog.\nPrivate Blogging: Hashnode Pro users can create private blogs that are not visible to the public. This feature is useful for those who want to share their personal thoughts with a select group of people.\nPriority support: Hashnode Pro users get priority support from the Hashnode team, which means that if they run into any issues, they get a quick response.\nI got to know about these features through internet, some videos and the official hashnode website. I think having you own newsletter and the being able to use custom CSS in your blog are the two best features of Hashnode pro. Having your own newsletter can open up a lot financial opportunities and would be a great way to connect with your followers. Other than that having no ads can be very helpful and know about your audience can be very helpful to write better selling blogs.\nWe can easily say, Blogging and making a personal brand in tech has never been easier. AI can handle the \u0026ldquo;undesirable part\u0026rdquo; of blogging so that you can focus on your content. Hashnode pro can be a great tool to play around if you financially well enough to buy it. In my humble opinion, definately Hashnode pro is a wroth it investment, at least I would do it in near future.\nThis article is around Hashnode Pro, but one awesome feature you get even for free is the Rix AL chatbot, that can help you around editing your blogs. Want an example, The conclusion of this blog has been written by Rix, so that I can focus on the main content. cool, right ?\nConclusion In conclusion, Hashnode Pro is a powerful platform for bloggers that offers many useful features including custom domains, custom CSS, newsletters, subscriber management, advanced analytics, team collaboration, and priority support. It also offers the advantage of having no ads on your blog and the ability to create private blogs. Although it comes at a cost, it is undoubtedly worth the investment for those who are financially capable of buying it. With Hashnode Pro, making a personal brand in the tech industry has never been easier. Additionally, the Rix AI chatbot is a useful and free feature that can help with editing your blogs. Overall, Hashnode Pro can greatly transform the way you approach blogging and can provide many opportunities for monetization and community building.\nI would like to end this article with this line someone told me when I was afraid of writing my first blog on Hashnode: \u0026ldquo;Just write it once. The worst-case is nobody reads it except you. Writing terrible blogs is inevitable, write terrible ones early so that you reach the point of writing better blogs early.\u0026rdquo;\nThank you for your time.\n","permalink":"//localhost:1313/blog/hashnode/","summary":"As someone who got to know the importance of developing a personal brand and learning in public, I restarted my blogging journey two months ago with Hashnode. Prior to that, I had been actively writing blogs on various platforms, including Blogger and WordPress for the past two years. Through this experience of two years of other blogging platforms and a short 2 months at Hashnode, I have firsthand experience of how powerful Hashnode and Hashnode Pro are compared to their competitors.","title":"Hashnode Pro: A worth-it Investment?"},{"content":"Recently while randomly scrolling Twitter, I stumbled upon a great tool for Building websites and applications. Not just this, this tool is used by professionals for Multilingual content management, Content localization and Managing content across multiple channels. I tried it and here is my experience of using Storyblok for the first time.\nWhat is this Content Management System? I am a beginner explain me in simpler terms. Imagine you have a website where you want to create, organize, and update various types of content ( articles, images, videos, etc). A Content Management System (CMS) is like a toolbox or a platform that helps you manage all of this content easily.\nInstead of manually writing code or editing HTML files every time you want to make a change, a CMS provides you with a user-friendly interface where you can create and edit your content using familiar tools, similar to using a word processor or a website builder. It allows you to focus on the content itself without worrying too much about the technical aspects.\nStoryblok is also a Content Management System, and in my view, It\u0026rsquo;s quite powerful!\nwhat is Storyblok and why Storyblok? Storyblok is a headless Content Management System (CMS) designed to help businesses create, manage, and deliver content across different digital platforms. It provides a user-friendly interface for content creators and developers to collaborate on building and maintaining websites, mobile apps, and other digital experiences. To answer why Storyblok, why not we just go and try it out.\nFollow these steps: Step 1. Go to the Storyblok website\nStep 2. Sign in or Sign up accordingly. As of now (16th June 2023) Storyblok is providing a 14-day free trial, 14 days would be enough for you to understand CMS and figure out if you wish to pursue it ahead.\nStep 3. Upon Signing into the website, you will be provided with a window of your spaces. Here is mine -\nStep 4. Now just follow the guide to get used-to to the multiple tools and features -\nStep 5. Try and experiment around various tools and features, and once you are done with the design, publish it.\nStep 6. Hurray! your brand new website is created and published in minutes. If you would sit and code such a website, it would have taken you days or even weeks depending upon the quality of the website. Here is a website that I created and published in less than 5 minutes\nThis is the power of a content management system. Now the question is \u0026ldquo;Why only Storyblok when there are multiple content management systems\u0026rdquo;. Firstly, to answer that, try it out, experiment around multiple such CMSs and figure out which one is the best for you. I specifically loved Storyblok for the following features it provides:\nHeadless Approach: Storyblok follows a headless CMS architecture, which provides greater flexibility in delivering content to multiple channels and platforms. It separates the backend content management from the frontend presentation, allowing you to reuse and repurpose content across various digital touchpoints.\nVisual Editing and User-Friendly Interface: Storyblok offers a visual editor that simplifies the content creation and editing process. Its intuitive interface empowers content creators with a WYSIWYG (What You See Is What You Get) experience, making it easy to create and manage content without the need for technical expertise.\nComponent-Based Content Creation: Storyblok embraces a component-based approach to content creation. You can define reusable content components, such as headers, blog posts, or product listings, and assemble them to build pages or templates. This modular structure enhances efficiency and consistency in content management.\nMultilingual and Localization Support: Storyblok provides robust multilingual and localization capabilities. You can easily manage content in multiple languages, streamline translation workflows, and customize localized experiences for different regions or target audiences.\nDeveloper-Friendly Tools and APIs: Storyblok offers extensive developer tools and APIs, enabling seamless integration with other systems and technologies. It supports popular frontend frameworks like React, Vue.js, and Angular, allowing developers to build dynamic and interactive frontend experiences while leveraging Storyblok\u0026rsquo;s content management capabilities.\nCollaborative Workflow: Storyblok facilitates collaborative content workflows with features like role-based access control, content versioning, and content approval processes. Team members can collaborate effectively, track changes, and maintain a structured content management process.\nScalability and Performance: Storyblok is designed to handle high-performance and scalable content delivery. It leverages a global CDN (Content Delivery Network) to ensure fast and reliable content distribution worldwide, enhancing user experiences across different regions.\nActive Community and Support: Storyblok has a vibrant community of developers, content creators, and support resources. You can access documentation, tutorials, and engage with the community to seek assistance, share experiences, and stay up-to-date with the latest developments.\nI tried multiple such content management systems, I kind of liked Storyblok more. But that might not be the same for you. so try out, get your hands dirty, after all the best way to learn is \u0026ldquo;learning by doing\u0026rdquo; rather than just reading a shitty blog by some unknown guy.\nConclusion In conclusion, Storyblok is a powerful and user-friendly Content Management System (CMS) that empowers businesses and developers to create and manage digital content across various platforms. Its headless architecture, visual editing, component-based content creation, multilingual and localization support, developer-friendly tools, and collaborative workflow features make it an excellent choice for building complex and dynamic digital experiences.\nThe platform enables faster and more efficient content creation and delivery, while also providing scalability and performance for high traffic websites and applications. Its active community and support resources ensure that users have access to help and guidance throughout their experience.\nIf you are looking for a flexible and robust CMS for your digital content needs, then Storyblok is definitely worth a try.\nThank you for reading this far. I hope you got some value out of it. Do follow me for more such content around tech and computer science.\nThank you for your time.\n","permalink":"//localhost:1313/blog/storybok/","summary":"Recently while randomly scrolling Twitter, I stumbled upon a great tool for Building websites and applications. Not just this, this tool is used by professionals for Multilingual content management, Content localization and Managing content across multiple channels. I tried it and here is my experience of using Storyblok for the first time.\nWhat is this Content Management System? I am a beginner explain me in simpler terms. Imagine you have a website where you want to create, organize, and update various types of content ( articles, images, videos, etc).","title":"Introduction to Storyblok: Transforming the Way You Create and Manage Content"},{"content":"Contributing to open-source projects as a beginner can be a little overwhelming. We come across many terms which might sound alien to us. I remember myself 3 months ago, trying to contribute to a beginner-friendly issue when the maintainer told me to \u0026ldquo;make a PR\u0026rdquo; and I didn\u0026rsquo;t know that PR actually is the short form for Pull Request.\nTo help you avoid the hurdles I faced and prevent time-consuming mistakes that I made while beginning my open-source contributions journey, I have curated a list of essential terms one must know, in order to begin his/her open-source contributions journey.\nBefore that one very important tip - Open-source is not about spoon-feeding, so you will have to learn things by yourself, by making mistakes and learning from them. Therefore is completely fine that you don\u0026rsquo;t understand what to do. how to raise an issue? how to merge a PR? Open-source is a community of the most supportive people in the world and everyone would love to help you once you get stuck at some place. So try out, fail and iterate, don\u0026rsquo;t expect people won\u0026rsquo;t answer you or think you are dumb. Don\u0026rsquo;t hesitate asking, but neither should you expect spoon-feeding.\nStarting from the very basics Git Git is a distributed version control system that helps developers manage and track changes in their code projects. It allows you to create a history of changes, switch between versions, and collaborate with others. Git stores code in repositories and track each change made, enabling easy branching, merging, and resolving conflicts. You can work offline and sync changes later. Git\u0026rsquo;s decentralized nature ensures multiple developers can work simultaneously without conflicts. It provides a reliable and efficient way to organize, share, and safeguard code, making it an essential tool for collaborative software development.\nGitHub GitHub is a web-based platform that hosts and manages Git repositories. GitHub will be the place where you will contribute to various open-source projects. It provides a centralized space for developers to collaborate on code projects. GitHub allows you to store your code, track changes, and work with others in a streamlined manner. It offers features like issue tracking, pull requests, and code review, facilitating collaboration and efficient development workflows. With GitHub, you can easily share your code, contribute to open-source projects, and showcase your work. It serves as a social platform for developers, fostering community engagement and making it a hub for version control and collaborative coding.\n","permalink":"//localhost:1313/blog/open-source101/","summary":"Contributing to open-source projects as a beginner can be a little overwhelming. We come across many terms which might sound alien to us. I remember myself 3 months ago, trying to contribute to a beginner-friendly issue when the maintainer told me to \u0026ldquo;make a PR\u0026rdquo; and I didn\u0026rsquo;t know that PR actually is the short form for Pull Request.\nTo help you avoid the hurdles I faced and prevent time-consuming mistakes that I made while beginning my open-source contributions journey, I have curated a list of essential terms one must know, in order to begin his/her open-source contributions journey.","title":"Open-Source 101: The basic must-know terms for an open-source beginner"},{"content":"OSI (Open Systems Interconnection) OSI (Open Systems Interconnection) model describes seven layers through which computer systems communicate over a network.\nRemember that, the modern Internet is not based on OSI, but on TCP/IP model (Transmission Control Protocol/ Internet Protocol)\nPhysical Layer: The physical layer is concerned with the physical transmission of data over a network. It defines the electrical, mechanical, and procedural aspects of the network hardware and cabling.\nData Link Layer: The data link layer establishes and maintains reliable links between adjacent nodes on a network. It handles the physical addressing of data packets and error detection and correction.\nNetwork Layer: The network layer is responsible for logical addressing and routing of data between different networks. It determines the best path for data packets to travel from source to destination.\nTransport Layer: The transport layer provides end-to-end communication services for applications. It ensures that data is transmitted reliably, efficiently, and securely between communicating devices.\nSession Layer: The session layer manages and coordinates communication sessions between applications on different devices. It establishes, maintains, and terminates communication sessions.\nPresentation Layer: The presentation layer defines the format and representation of data exchanged between applications. It manages data compression, encryption, and decryption.\nApplication Layer: The application layer provides services directly to end-users. It specifies how user applications interact with the network and enables users to access network resources and services.\nOverall, the OSI model helps to streamline network communication by breaking the process down into smaller and manageable components. By having a clear understanding of the OSI model and how it works, network engineers can work more effectively and efficiently to design, implement, manage, and troubleshoot networks.\n","permalink":"//localhost:1313/blog/osi/","summary":"OSI (Open Systems Interconnection) OSI (Open Systems Interconnection) model describes seven layers through which computer systems communicate over a network.\nRemember that, the modern Internet is not based on OSI, but on TCP/IP model (Transmission Control Protocol/ Internet Protocol)\nPhysical Layer: The physical layer is concerned with the physical transmission of data over a network. It defines the electrical, mechanical, and procedural aspects of the network hardware and cabling.\nData Link Layer: The data link layer establishes and maintains reliable links between adjacent nodes on a network.","title":"OSI Model - the easy way"},{"content":"DevOps can be a bit confusing for beginners, that is because of its complex terminologies. Here are some terms you must know as a DevOps beginner.\nAgile: is an iterative approach to project management and software development that helps teams deliver value to their customers faster and with fewer issues.\nClient-server architecture: is a distributed application structure that partitions tasks or workloads between the providers of a resource or service, called servers, and service requesters, called clients.\nA container: powered by the containerization engine, is a standard unit of software that encapsulates the application code, runtime, system tools, system libraries, and settings necessary for programmers to efficiently build, ship and run applications.\nContainer Registry: Used for the storage and distribution of named container images. While many features can be built on top of a registry, its most basic functions are to store images and retrieve them.\nContainer Registry: Used for the storage and distribution of named container images. While many features can be built on top of a registry, its most basic functions are to store images and retrieve them.\nCI/CD pipelines: A continuous integration and continuous deployment (CI/CD) pipeline is a series of steps that must be performed in order to deliver a new version of software. CI/CD pipelines are a practice focused on improving software delivery throughout the software development life cycle via automation.\nCloud native: A cloud-native application is a program that is designed for a cloud computing architecture. These applications are run and hosted in the cloud and are designed to capitalize on the inherent characteristics of a cloud computing software delivery model.\nDaemon-less: A container runtime that does not run any specific program (daemon) to create objects, such as images, containers, networks, and volumes.\nDevOps: is a set of practices, tools, and a cultural philosophy that automate and integrate the processes between software development and IT teams.\nDocker: An open container platform for developing, shipping and running applications in containers.\nA Dockerfile: is a text document that contains all the commands you would normally execute manually in order to build a Docker image. Docker can build images automatically by reading the instructions from a Dockerfile.\nDocker client: is the primary way that many Docker users interact with Docker. When you use commands such as docker run, the client sends these commands to dockerd, which carries them out. The docker command uses the Docker API. The Docker client can communicate with more than one daemon.\nDocker Command Line Interface (CLI) The Docker client provides a command line interface (CLI) that allows you to issue build, run, and stop application commands to a Docker daemon.\nDocker daemon (dockerd) creates and manages Docker objects, such as images, containers, networks, and volumes.\nDocker Hub: is the world\u0026rsquo;s easiest way to create, manage, and deliver your team\u0026rsquo;s container applications.\nDocker localhost: Docker provides a host network which lets containers share your host’s networking stack. This approach means that a localhost in a container resolves to the physical host, instead of the container itself.\nDocker remote host: A remote Docker host is a machine, inside or outside our local network which is running a Docker Engine and has ports exposed for querying the Engine API.\nDocker networks: help isolate container communications.\nDocker plugins: such as a storage plugin, provides the ability to connect external storage platforms.\nDocker storage: uses volumes and bind mounts to persist data even after a running container is stopped.\nLXC: LinuX Containers is a OS-level virtualization technology that allows creation and running of multiple isolated Linux virtual environments (VE) on a single control host.\nIBM Cloud Container Registry: stores and distributes container images in a fully managed private registry.\nImage: An immutable file that contains the source code, libraries, and dependencies that are necessary for an application to run. Images are templates or blueprints for a container.\nImmutability: Images are read-only; if you change an image, you create a new image.\nMicroservices: are a cloud-native architectural approach in which a single application contains many loosely coupled and independently deployable smaller components or services.\nNamespace: A Linux namespace is a Linux kernel feature that isolates and virtualizes system resources. Processes which are restricted to a namespace can only interact with resources or processes that are part of the same namespace. Namespaces are an important part of Docker’s isolation model. Namespaces exist for each type of resource, including networking, storage, processes, hostname control and others.\nOperating System Virtualization: OS-level virtualization is an operating system paradigm in which the kernel allows the existence of multiple isolated user space instances, called containers, zones, virtual private servers, partitions, virtual environments, virtual kernels, or jails.\nPrivate Registry: Restricts access to images so that only authorized users can view and use them.\nREST API: A REST API (also known as RESTful API) is an application programming interface (API or web API) that conforms to the constraints of REST architectural style and allows for interaction with RESTful web services.\nRegistry: is a hosted service containing repositories of images which responds to the Registry API.\nRepository: is a set of Docker images. A repository can be shared by pushing it to a registry server. The different images in the repository can be labelled using tags.\nServer Virtualization: Server virtualization is the process of dividing a physical server into multiple unique and isolated virtual servers by means of a software application. Each virtual server can run its own operating systems independently.\nServerless: is a cloud-native development model that allows developers to build and run applications without having to manage servers.\nTag: A tag is a label applied to a Docker image in a repository. Tags are how various images in a repository are distinguished from each other.\n","permalink":"//localhost:1313/blog/devops/","summary":"DevOps can be a bit confusing for beginners, that is because of its complex terminologies. Here are some terms you must know as a DevOps beginner.\nAgile: is an iterative approach to project management and software development that helps teams deliver value to their customers faster and with fewer issues.\nClient-server architecture: is a distributed application structure that partitions tasks or workloads between the providers of a resource or service, called servers, and service requesters, called clients.","title":"Some DevOps terms a beginner should know about"},{"content":"We often come through JSON files during developing web applications. you must have noticed that the JSON files store data in the form of a bunch of key-value pairs. JSON is often used in web development frameworks such as React and Angular, as well as in backend frameworks such as Node.js and Django.\nJSON JSON stands for JavaScript Object Notation. It is a lightweight data-interchange format that is easy for humans to read and write, and easy for machines to parse and generate.\nWhy is it so widely used? JSON is very lightweight, easy to read and integrates smoothly with JavaScript. That\u0026rsquo;s the main reason why it is used mostly in web dev, rather than XML. JSON is often used to transmit data between a server and a web application, as an alternative to XML. In JSON, data is represented as key-value pairs, similar to objects in many programming languages.\n{ \u0026#34;name\u0026#34;: \u0026#34;Shubham\u0026#34;, \u0026#34;age\u0026#34;: 19, \u0026#34;isMarried\u0026#34;: false, \u0026#34;skills\u0026#34;: [\u0026#34;web dev\u0026#34;, \u0026#34;devops\u0026#34;, \u0026#34;android dev\u0026#34;] } JSON was first introduced in 2002 by Douglas Crockford, who is also known for his work on JavaScript and the development of the JSON standard. Some alternatives to JSON are XML (Extensible Markup Language), and YAML (Yet Another Markup Language).\nThis marks the end of this article, Thanks for your time. Do check out my other articles on tech-related terminologies.\n","permalink":"//localhost:1313/blog/json/","summary":"We often come through JSON files during developing web applications. you must have noticed that the JSON files store data in the form of a bunch of key-value pairs. JSON is often used in web development frameworks such as React and Angular, as well as in backend frameworks such as Node.js and Django.\nJSON JSON stands for JavaScript Object Notation. It is a lightweight data-interchange format that is easy for humans to read and write, and easy for machines to parse and generate.","title":"WTF is JSON"},{"content":"You might remember using npm start in your React app or using pip in python. Both npm and pip are package managers of their respective languages. Therefore the technical definition of package manager is -\n\u0026ldquo;A package manager is a tool used in software development to manage the installation, updating, and removal of software packages or libraries.\u0026rdquo;\nPackage managers automate the process of searching, installing, and maintaining these packages, which makes it easier for developers to include them in their projects. Instead of manually downloading and installing each package separately, developers can use the package manager to handle all the dependencies and ensure that the necessary versions are installed.\nThere are two main types of package managers:\nSystem-Level Package Managers: These package managers are used to manage packages at the operating system level. Examples of system-level package managers include Aptitude (used in Debian and Ubuntu), YUM (used in CentOS and Fedora), and Homebrew (used in macOS).\nLanguage-Specific Package Managers: These package managers are used to manage packages specific to a programming language. Examples of language-specific package managers include npm (used in Node.js), pip (used in Python), Composer (used in PHP), and NuGet (used in .NET).\nIn conclusion, a package manager is a tool that automates the process of managing software dependencies by allowing developers to search, install, and update packages or libraries easily. The use of a package manager saves time and reduces duplication of effort by automating the handling of dependencies. Almost every programming language has its own package manager, and using one has become a critical part of modern software development workflows.\n","permalink":"//localhost:1313/blog/npm/","summary":"You might remember using npm start in your React app or using pip in python. Both npm and pip are package managers of their respective languages. Therefore the technical definition of package manager is -\n\u0026ldquo;A package manager is a tool used in software development to manage the installation, updating, and removal of software packages or libraries.\u0026rdquo;\nPackage managers automate the process of searching, installing, and maintaining these packages, which makes it easier for developers to include them in their projects.","title":"WTF is JSON"},{"content":"So recently, I was setting up locally an open-source software, so to contribute to it (BTW it is called Zulip, Please check it out - it\u0026rsquo;s an amazing org). And its documentation said me to download Vagrant in order to run it locally on Windows. I researched about it and this is what I got to know -\n\u0026ldquo;Vagrant is a tool that helps developers to create and manage virtual machines (VMs) or lightweight, reproducible development environments.\u0026rdquo;\nIt is an open-source tool. It automates the process of creating and configuring virtual machines, making it easier for developers to work on multiple projects with different system requirements on a single machine.\nWith Vagrant, you can use provisioners to install software, configure environments, and integrate with other tools like Ansible, Chef, and Puppet. You can also share and distribute your VMs easily with your team or community, making it a popular choice for collaborative workflows.\nVagrant can be used with various virtualization technologies, including VirtualBox, VMware, and Hyper-V, on Windows, macOS, and Linux platforms.\nAnd that\u0026rsquo;s it. Thank you for your time. Follow my blog for more such articles.\n","permalink":"//localhost:1313/blog/vagrant/","summary":"So recently, I was setting up locally an open-source software, so to contribute to it (BTW it is called Zulip, Please check it out - it\u0026rsquo;s an amazing org). And its documentation said me to download Vagrant in order to run it locally on Windows. I researched about it and this is what I got to know -\n\u0026ldquo;Vagrant is a tool that helps developers to create and manage virtual machines (VMs) or lightweight, reproducible development environments.","title":"WTF is Vagrant"},{"content":"What is YAML? YAML (which stands for \u0026ldquo;YAML Ain\u0026rsquo;t Markup Language\u0026rdquo;) is a human-readable data serialization language. We will talk later about what a serialization language is.\nYAML is used for configuration files, exchanging data between programming languages and storing data. YAML files are extensively used in the DevOps field. YAML is considered better than its alternative because of its easy-to-read way.\nIt is often used for configuration files, data exchange between programming languages, and storing data in a structured and easy-to-read way.\nYAML files are denoted by \u0026quot;.YML\u0026quot; OR \u0026quot;.YAML\u0026quot;.\nInitially, YAML was called \u0026ldquo;Yet Another Markup Language\u0026rdquo;. but the name was changed to simply \u0026ldquo;YAML Ain\u0026rsquo;t Markup Language\u0026rdquo; (or just YAML) in order to emphasize that YAML is not just another markup language like XML or HTML, but rather a data serialization language that is more human-readable and easier to work with.\nExample of YAML file: This file includes almost all important YAML concepts. It\u0026rsquo;s a bit lengthy but very important to understand the concepts of YAML. Do check it out.\n\u0026#34;name\u0026#34;: \u0026#34;Shubham\u0026#34; # key value pairs --- # lists \u0026#34;list\u0026#34;: - \u0026#34;apple\u0026#34; - \u0026#34;mango\u0026#34; - \u0026#34;three\u0026#34; - four --- # documents are seperated by --- # \u0026#34;...\u0026#34; denotes that documents has ended # String variables -\u0026gt; a: \u0026#34;string\u0026#34; b: string c: \u0026#39;string\u0026#39; float: 10.12 int: 23 boolean: No #n , N, false, False, FALSE booleanTwo: Yes #y, Y, True, true, TRUE nulltext: Null #null NULL --- d: | This is how we write multi line data e: \u0026gt; This is how we write one line data in multiple lines # specify the type: zero: !!int 0 commaValue: !!int +100_000 #equivalent to 100,000 booleanThree: !!bool Yes stringtwo: !!str \u0026#34;Shubham\u0026#34; floatTwo: !!float 12.12 nulltext: !!null Null #null NULL # maps: key value pairs map example: name: Shubham age: 19 country: India # another way of representing a map map example two: {name: Shubham, age: 19, country: India} # sets are used to store items expertise: !!set ? Web dev ? Android dev ? DevOps # Dictionary or !!omap students: !!omap - Shubham: age: 19 - Ram: age: 23 - Shayam: age: 24 # Using anchors age_and_gender: \u0026amp;19_and_male gender: male age: 19 person1: name: Shubham \u0026lt;\u0026lt;: *19_and_male person2: name: Ram \u0026lt;\u0026lt;: *19_and_male Data serialization: Data serialization is the process of converting data from one format to another. When data is serialized, it is transformed into a format that can be easily stored or transmitted across different applications or systems.\nThe reverse process of converting the serialized data back to its original format is called deserialization.\nFor Data serialization, we use the data serialization formats like JSON, YAML and XML. YAML is one of the more popular options out of these. JSON and YAML are more human-readable than XML.\nAdvantages of YAML: Here are some benefits of YAML:\nHuman-readable: One of the biggest benefits of YAML is that it is easy for humans to read and write. Unlike JSON or XML, YAML documents use simple indentation and whitespace to structure data, making them easier to understand and modify.\nSupports complex data structures: YAML supports a wide range of data structures, including lists, dictionaries, and nested structures, making it ideal for working with complex data.\nLanguage agnostic: YAML is language agnostic, meaning that it can be used with any programming language without requiring any special libraries or tools.\nLess verbose: YAML generally requires less syntax compared to other data serialization formats like JSON or XML, making it cleaner and more concise.\nSupports comments: YAML supports comments, which allow developers to add notes and explanations within the document.\nGreat for configuration files: YAML is commonly used for configuration files, such as those used in Docker or Kubernetes, because of its simplicity and readability.\nThese benefits make YAML a popular choice for developers looking for a data serialization format that is easy to work with and supports a wide range of data structures.\nConclusion: In conclusion, YAML is a simple, human-readable data serialization format that allows developers to easily exchange and store data across different programming languages and systems. Its support for complex data structures, language agnosticism, and support for comments, make it an ideal choice for developers working in the DevOps field or those dealing with configuration files. With its intuitive syntax and streamlining of complex data structures, YAML is becoming a popular choice for developers looking to improve readability and maintainability of their code.\n","permalink":"//localhost:1313/blog/yaml/","summary":"What is YAML? YAML (which stands for \u0026ldquo;YAML Ain\u0026rsquo;t Markup Language\u0026rdquo;) is a human-readable data serialization language. We will talk later about what a serialization language is.\nYAML is used for configuration files, exchanging data between programming languages and storing data. YAML files are extensively used in the DevOps field. YAML is considered better than its alternative because of its easy-to-read way.\nIt is often used for configuration files, data exchange between programming languages, and storing data in a structured and easy-to-read way.","title":"YAML - from basics to advanced"},{"content":"🔗 Code Buddy Description Code Buddy is a place for coders to find their buddies - find a coding partner for hackathons, events and just chilling out. find programmers near you, Sort by location, technology, and shared interests.\nTech Stack used - React Golang ","permalink":"//localhost:1313/projects/code-buddy/","summary":"🔗 Code Buddy Description Code Buddy is a place for coders to find their buddies - find a coding partner for hackathons, events and just chilling out. find programmers near you, Sort by location, technology, and shared interests.\nTech Stack used - React Golang ","title":"Code Buddy"},{"content":"","permalink":"//localhost:1313/learn-devops/kubernetes/","summary":"","title":"Learn Kubernetes - A beginners Guide"},{"content":"Rapport du Stagiaire : Stage de Découverte chez Orange Introduction Je m\u0026rsquo;appelle Mouad , et j\u0026rsquo;ai eu la chance de participer à un stage de découverte chez Orange pendant 5 jours. Au cours de ce stage, j\u0026rsquo;ai exploré l\u0026rsquo;univers passionnant des télécommunications et découvert comment Orange nous aide à communiquer et utiliser Internet. Découverte de l\u0026rsquo;univers d\u0026rsquo;Orange Le premier jour du stage, j\u0026rsquo;ai appris ce qu\u0026rsquo;est Orange et comment cette entreprise nous aide à communiquer. J\u0026rsquo;ai eu l\u0026rsquo;opportunité de visiter les locaux d\u0026rsquo;Orange d\u0026rsquo;Orange Village à arcueil et de rencontrer des employés passionnés par leur travail. Visite d\u0026rsquo;un laboratoire informatique J\u0026rsquo;ai visité un laboratoire informatique où j\u0026rsquo;ai pu observer différentes technologies en action. Visite des locaux d\u0026rsquo;Orange Innovation à Chatillon J\u0026rsquo;ai visité les locaux d\u0026rsquo;Orange Innovation à Chatillon où j\u0026rsquo;ai découvert les dernières innovations technologiques développées par Orange. Les métiers chez Orange Le quatrième jour a été consacré à la découverte des différents métiers chez Orange. J\u0026rsquo;ai eu l\u0026rsquo;occasion de rencontrer des professionnels et de poser des questions sur leur travail. Visite d\u0026rsquo;un datacenter à Paris J\u0026rsquo;ai visité un datacenter à Paris où j\u0026rsquo;ai pu observer les serveurs, les salles électriques et les équipements de climatisation utilisés par Orange pour maintenir ses services en ligne. Conclusion Ce stage de découverte chez Orange a été une expérience incroyable pour moi. J\u0026rsquo;ai appris énormément de choses sur les télécommunications et j\u0026rsquo;ai rencontré des personnes passionnantes. Je suis reconnaissant d\u0026rsquo;avoir eu cette opportunité et j\u0026rsquo;espère pouvoir continuer à explorer ce domaine à l\u0026rsquo;avenir. ","permalink":"//localhost:1313/stage2024/stage/","summary":"Rapport du Stagiaire : Stage de Découverte chez Orange Introduction Je m\u0026rsquo;appelle Mouad , et j\u0026rsquo;ai eu la chance de participer à un stage de découverte chez Orange pendant 5 jours. Au cours de ce stage, j\u0026rsquo;ai exploré l\u0026rsquo;univers passionnant des télécommunications et découvert comment Orange nous aide à communiquer et utiliser Internet. Découverte de l\u0026rsquo;univers d\u0026rsquo;Orange Le premier jour du stage, j\u0026rsquo;ai appris ce qu\u0026rsquo;est Orange et comment cette entreprise nous aide à communiquer.","title":"Stage de Découverte chez Orange : Rapport du Stagiaire"},{"content":"web server https://github.com/1Shubham7/web-server ","permalink":"//localhost:1313/projects/web-server/","summary":"web server https://github.com/1Shubham7/web-server ","title":"Web Server"},{"content":"","permalink":"//localhost:1313/projects/mission-health/","summary":"","title":""}]